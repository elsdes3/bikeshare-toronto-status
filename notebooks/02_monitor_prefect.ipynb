{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c4c2a2-8d97-4604-b97e-506958780876",
   "metadata": {},
   "source": [
    "# Query Prefect Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d89307-f03d-4bf4-a9a9-ed991edff38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import toml\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import polars as pl\n",
    "import pytz\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ccfe2-0770-471e-b3f4-dc243bb4f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pl.Config.set_tbl_cols(50)\n",
    "_ = pl.Config.set_fmt_str_lengths(1_000)\n",
    "_ = pl.Config.set_tbl_width_chars(1_000)\n",
    "_ = pl.Config.set_tbl_rows(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4f620-1b03-4dc3-a9dd-bfeca2ca917c",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8bd824-8317-4eec-aec8-19caa390237e",
   "metadata": {},
   "source": [
    "Inspect various Prefect Cloud resources using the [Prefect Cloud REST API](https://app.prefect.cloud/api/docs?deviceId=a33a4353-797d-467c-a50c-b6811e99f347)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02f895-59ba-4c0c-9219-f5f820d1add0",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f4ec5-d736-4f42-bab7-a5379ecab5c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "flow_name = \"status-flow\"\n",
    "deployment_name = \"get-status-deployment\"\n",
    "s3_bucket_name = \"bikeshare-toronto-dash\"\n",
    "\n",
    "my_timezone = 'America/Toronto'\n",
    "\n",
    "work_queues_cols = [\n",
    "    'id',\n",
    "    'name',\n",
    "    # 'updated',\n",
    "    'is_paused',\n",
    "    'last_polled',\n",
    "    # 'work_pool_id',\n",
    "    'work_pool_name',\n",
    "]\n",
    "flow_run_cols = [\n",
    "    'name',\n",
    "    # 'id',\n",
    "    # 'created',\n",
    "    # 'updated',\n",
    "    'flow_name',\n",
    "    # 'state_id',\n",
    "    'deployment_id',\n",
    "    # 'flow_version',\n",
    "    # 'parameters',\n",
    "    # 'idempotency_key',\n",
    "    # 'context',\n",
    "    # 'empirical_policy',\n",
    "    # 'tags',\n",
    "    # 'parent_task_run_id',\n",
    "    # 'state_type',\n",
    "    # 'state_name',\n",
    "    'run_count',\n",
    "    # 'expected_start_time',\n",
    "    # 'next_scheduled_start_time',\n",
    "    'start_time',\n",
    "    # 'end_time',\n",
    "    'total_run_time',\n",
    "    # 'estimated_run_time',\n",
    "    # 'estimated_start_time_delta',\n",
    "    'auto_scheduled',\n",
    "    # 'infrastructure_document_id',\n",
    "    # 'infrastructure_pid',\n",
    "    # 'created_by',\n",
    "    # 'work_queue_id',\n",
    "    'work_queue_name',\n",
    "    # 'work_pool_id',\n",
    "    'work_pool_name',\n",
    "    # 'state',\n",
    "]\n",
    "deployment_cols = [\n",
    "    'id',\n",
    "    # 'created',\n",
    "    'updated',\n",
    "    'name',\n",
    "    'version',\n",
    "    'description',\n",
    "    'flow_id',\n",
    "    # 'schedule',\n",
    "    'is_schedule_active',\n",
    "    # 'infra_overrides',\n",
    "    # 'parameters',\n",
    "    'status',\n",
    "    # 'last_polled',\n",
    "    # 'pull_steps',\n",
    "    # 'tags',\n",
    "    'work_queue_name',\n",
    "    # 'parameter_openapi_schema',\n",
    "    # 'path',\n",
    "    # 'entrypoint',\n",
    "    # 'manifest_path',\n",
    "    # 'storage_document_id',\n",
    "    # 'infrastructure_document_id',\n",
    "    # 'created_by',\n",
    "    # 'updated_by',\n",
    "    'work_pool_name',\n",
    "    'enforce_parameter_schema',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1df588-6592-42fa-ab85-56f96ff3e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORIES\n",
    "prefect_dir = os.path.join(os.path.expanduser(\"~\"), \".prefect\")\n",
    "\n",
    "# FILE PATHS\n",
    "profiles_fpath = os.path.join(prefect_dir, \"profiles.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd64ea2c-2a51-4456-acf4-446fdec8aac2",
   "metadata": {},
   "source": [
    "## Pre-Requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43a0c9-1809-44f3-86dc-7edfdd73f10e",
   "metadata": {},
   "source": [
    "### Load Prefect Profiles File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1109cd-d41d-44a7-8031-409cfe63b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = toml.load(profiles_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e6db6-2a90-4b17-9e5a-f55bc8fbd822",
   "metadata": {},
   "source": [
    "### Get Prefect Server REST API URL for Prefect Cloud and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8b302-6655-49d4-a386-f25cff781c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefect_cloud_creds = profiles[\"profiles\"][\"cloud\"]\n",
    "api_base_url = prefect_cloud_creds[\"PREFECT_API_URL\"]\n",
    "api_key = prefect_cloud_creds[\"PREFECT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84387836-5b05-4c56-a841-9bb8859be2a4",
   "metadata": {},
   "source": [
    "### Get REST API Authentication Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884ebb0-18f6-4196-a6ca-1864bb8871f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_headers = dict(\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c1081-d6e9-4b51-a8b2-e028403a1bd6",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7533f3e-8072-4c8b-b91e-b921f3a7ec72",
   "metadata": {},
   "source": [
    "### Retrieve Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356b543-d793-4ca3-b2be-7099c20b4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = requests.post(\n",
    "    f\"{api_base_url}/flows/filter\",\n",
    "    **auth_headers,\n",
    ")\n",
    "assert r.status_code == 200\n",
    "df_flows = (\n",
    "    pl.from_records(r.json())\n",
    "    .filter(pl.col('name') == flow_name)\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.col(c)\n",
    "            .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.f%Z\")\n",
    "            .dt.replace_time_zone('UTC')\n",
    "            .dt.convert_time_zone(my_timezone)\n",
    "            for c in ['created', 'updated']\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "df_flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51e729-48de-4558-a3ce-69fa0a57a236",
   "metadata": {},
   "source": [
    "### Retrieve Deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98bc20-f3c7-4bbb-8e7d-4468efe15103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = requests.post(\n",
    "    f\"{api_base_url}/deployments/filter\",\n",
    "    json={\n",
    "        \"sort\": \"NAME_ASC\",\n",
    "        'deployment': {'name': deployment_name},\n",
    "        # 'status': 'READY',\n",
    "        \"limit\": 1,\n",
    "    },\n",
    "    **auth_headers\n",
    ")\n",
    "assert r.status_code == 200\n",
    "df_deployments = (\n",
    "    pl.from_records(r.json())\n",
    "    .select([c for c in deployment_cols])\n",
    "    .rename(\n",
    "        {\n",
    "            \"id\": \"deployment_id\",\n",
    "            'name': \"deployment_name\",\n",
    "            'updated': \"deployment_updated\",\n",
    "            'version': 'deployment_version',\n",
    "        }\n",
    "    )\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.col(c)\n",
    "            .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.f%Z\")\n",
    "            .dt.replace_time_zone('UTC')\n",
    "            .dt.convert_time_zone(my_timezone)\n",
    "            for c in ['deployment_updated']\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "df_deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b64694-b815-40da-9502-69e5e79be5d0",
   "metadata": {},
   "source": [
    "### Retrieve Work Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34928b-0679-4ee2-82c0-0cf56cef6595",
   "metadata": {},
   "source": [
    "Get work queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672c346-21a9-4d80-a7fc-493aef6c7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = requests.post(\n",
    "    f\"{api_base_url}/work_queues/filter\",\n",
    "    **auth_headers,\n",
    ")\n",
    "assert r.status_code == 200\n",
    "df_work_queues = (\n",
    "    pl.from_records(r.json())\n",
    "    .filter(pl.col('name') != 'default')\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.col(c)\n",
    "            .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.f%Z\")\n",
    "            .dt.replace_time_zone('UTC')\n",
    "            .dt.convert_time_zone(my_timezone)\n",
    "            for c in ['created', 'updated', 'last_polled']\n",
    "        ]\n",
    "    )\n",
    "    .select(work_queues_cols)\n",
    "    .rename(\n",
    "        {\n",
    "            'id': \"work_queue_id\",\n",
    "            \"name\": \"work_queue_name\",\n",
    "            'is_paused': 'work_queue_is_paused',\n",
    "            'last_polled': \"work_queue_last_polled\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df_work_queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759a644-b4fc-403f-a725-b890f0900980",
   "metadata": {},
   "source": [
    "Get status for each work queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885228a-6808-47ad-a760-c36ad0a4536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs_work_queues_status = []\n",
    "for row in df_work_queues.rows():\n",
    "    r = requests.get(\n",
    "        f\"{api_base_url}/work_queues/{row[0]}/status\",\n",
    "        **auth_headers,\n",
    "    )\n",
    "    assert r.status_code == 200\n",
    "    df_work_queues_status = (\n",
    "        pl.from_records([r.json()])\n",
    "        .with_columns(\n",
    "        [\n",
    "            pl.col(c)\n",
    "            .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.f%Z\")\n",
    "            .dt.replace_time_zone('UTC')\n",
    "            .dt.convert_time_zone(my_timezone)\n",
    "            for c in ['last_polled']\n",
    "        ]\n",
    "    )\n",
    "        .rename(\n",
    "            {\n",
    "                \"healthy\": \"work_queue_healthy\",\n",
    "                \"late_runs_count\": \"work_queue_late_runs_count\",\n",
    "                \"last_polled\": \"work_queue_last_polled\",\n",
    "                \"health_check_policy\": \"work_queue_health_check_policy\",\n",
    "            }\n",
    "        )\n",
    "        .with_columns(pl.lit(row[0]).alias('work_queue_id'))\n",
    "    )\n",
    "    dfs_work_queues_status.append(df_work_queues_status)\n",
    "df_work_queues_status = pl.concat(dfs_work_queues_status)\n",
    "df_work_queues_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546538f8-7ead-424f-b72d-775d46085396",
   "metadata": {},
   "source": [
    "Append status to work queues metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1746d-9011-4495-8164-c925f2112694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work_queues = (\n",
    "    df_work_queues\n",
    "    .join(\n",
    "        df_work_queues_status,\n",
    "        on=['work_queue_id', 'work_queue_last_polled'],\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "df_work_queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd2b43-a0d4-4abd-9036-9da7e1dd8fcc",
   "metadata": {},
   "source": [
    "Perform sanity check after `LEFT JOIN` to append status to work queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c45ca3-174f-427a-9ed5-c3675696c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_work_queues.filter(pl.col('work_queue_health_check_policy') == \"{None,None}\").is_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f327b6-8657-4d7d-bec3-534d2119542e",
   "metadata": {},
   "source": [
    "### Retrieve Completed Flow Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351c22c-0a3c-4456-900a-e47a758892ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "r = requests.post(\n",
    "    f\"{api_base_url}/flow_runs/filter\",\n",
    "    json={\n",
    "        \"sort\": \"START_TIME_DESC\",\n",
    "        'flows': {'name': {'any_': [flow_name]}},\n",
    "        # 'flow_runs': {'state': {'name': {'any_': ['Completed']}}},\n",
    "        'deployments': {'name': {'any_': [deployment_name]}},\n",
    "        \"limit\": 50,\n",
    "    },\n",
    "    **auth_headers\n",
    ")\n",
    "assert r.status_code == 200\n",
    "df_flows_runs_completed = (\n",
    "    # flows\n",
    "    df_flows\n",
    "    .select([pl.col(c) for c in [\"id\", \"name\"]])\n",
    "    .rename({\"id\": \"flow_id\", \"name\": \"flow_name\"})\n",
    "    # flow runs\n",
    "    .join(pl.from_records(r.json()), on=\"flow_id\", how=\"left\")\n",
    "    .filter(pl.col('state_name') == 'Completed')\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.col(c)\n",
    "            .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.f%Z\")\n",
    "            .dt.replace_time_zone('UTC')\n",
    "            .dt.convert_time_zone(my_timezone)\n",
    "            for c in [\n",
    "                'start_time',\n",
    "                'end_time',\n",
    "                'created',\n",
    "                'updated',\n",
    "                'expected_start_time',\n",
    "                'next_scheduled_start_time',\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    .with_columns(\n",
    "        [\n",
    "            (\n",
    "                (pl.col('start_time')-pl.col('expected_start_time'))\n",
    "                .dt.nanoseconds()/10**9\n",
    "            )\n",
    "            .alias('start_delay')\n",
    "        ]\n",
    "    )\n",
    "    .select(flow_run_cols+['start_delay'])\n",
    "    # deployments\n",
    "    .join(\n",
    "        (\n",
    "            df_deployments\n",
    "            .select(['deployment_id', 'deployment_name', 'deployment_version'])\n",
    "        ),\n",
    "        on='deployment_id',\n",
    "        how='left',\n",
    "    )\n",
    "    # work queues\n",
    "    .join(\n",
    "        df_work_queues.drop(*['work_queue_id']),\n",
    "        on=['work_queue_name', 'work_pool_name'],\n",
    "        how='left',\n",
    "    )\n",
    "    .drop(*['deployment_id'])\n",
    ")\n",
    "df_flows_runs_completed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a3eeb2-050e-4d2b-9848-279ae9853289",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "1. Merging with `/work_queues` is optional since the last polled datetime is also available through the `/deployments` endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bf940-13cd-4034-865a-1f7233de0d83",
   "metadata": {},
   "source": [
    "### Retrieve Scheduled Flow Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62103fc2-14f8-4224-85bb-78e1fed36de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "r = requests.post(\n",
    "    f\"{api_base_url}/flow_runs/filter\",\n",
    "    json={\n",
    "        \"sort\": \"NEXT_SCHEDULED_START_TIME_ASC\",\n",
    "        'flows': {'name': {'any_': [flow_name]}},\n",
    "        'flow_runs': {'state': {'name': {'any_': ['Scheduled']}}},\n",
    "        'deployments': {'name': {'any_': [deployment_name]}},\n",
    "        \"limit\": 3,\n",
    "    },\n",
    "    **auth_headers\n",
    ")\n",
    "assert r.status_code == 200\n",
    "df_flows_runs_scheduled = (\n",
    "    # flows\n",
    "    df_flows\n",
    "    .select([pl.col(c) for c in [\"id\", \"name\"]])\n",
    "    .rename({\"id\": \"flow_id\", \"name\": \"flow_name\"})\n",
    "    # flow runs\n",
    "    .join(pl.from_records(r.json()), on=\"flow_id\", how=\"left\")\n",
    "    .filter(pl.col('state_name') == 'Scheduled')\n",
    "    .with_columns(\n",
    "        [\n",
    "            pl.col(c)\n",
    "            .str.to_datetime(\"%Y-%m-%dT%H:%M:%S%.f%Z\")\n",
    "            .dt.replace_time_zone('UTC')\n",
    "            .dt.convert_time_zone(my_timezone)\n",
    "            for c in [\n",
    "                # 'start_time',\n",
    "                # 'end_time',\n",
    "                'created',\n",
    "                'updated',\n",
    "                'expected_start_time',\n",
    "                'next_scheduled_start_time',\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    .with_columns(\n",
    "        [\n",
    "            (\n",
    "                (pl.col('next_scheduled_start_time')-datetime.now(tz=pytz.timezone(my_timezone)))\n",
    "                .dt.nanoseconds()/10**9/60\n",
    "            )\n",
    "            .alias('next_start')\n",
    "        ]\n",
    "    )\n",
    "    .select(flow_run_cols+['next_start', 'next_scheduled_start_time'])\n",
    "    # deployments\n",
    "    .join(\n",
    "        (\n",
    "            df_deployments\n",
    "            .select(['deployment_id', 'deployment_name', 'deployment_version'])\n",
    "        ),\n",
    "        on='deployment_id',\n",
    "        how='left',\n",
    "    )\n",
    "    # work queues\n",
    "    .join(\n",
    "        df_work_queues.drop(*['work_queue_id']),\n",
    "        on=['work_queue_name', 'work_pool_name'],\n",
    "        how='left',\n",
    "    )\n",
    "    .drop(*['deployment_id'])\n",
    ")\n",
    "df_flows_runs_scheduled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc962c14-5f92-49f5-b085-24332bcda8a2",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "1. This could also be retrieved by querying `/deployments/get_scheduled_flow_runs`.\n",
    "2. Merging with `/work_queues` is optional since the last polled datetime is also available through the `/deployments` endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb68f4b-c796-40bf-98a8-b8226df5eb29",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
